# Vanilla-GAN-and-proGAN
Utilize GAN and proGAN to generate images size 32x32 belonging to class 8 - "ship" from the CIFAR10 dataset

Reference: [Paper]https://arxiv.org/abs/1710.10196 |

## 1. Installation

(1) install all the necessary packages for the project mentioned in file `requirements.txt`

```
pip install -r requirements.txt
```
(2) Generate images using the pre-trained model:

**For Vanilla Mode:**

```
# Load the Generator from saved model
g_model = keras.models.load_model("/content/generated_1/g_model.sav")

# Generate 100 fake images by passing 128-dimensional random vectors through the Generator.
X_fake, _ = generate_fake_samples(g_model, 128, 100)
```
**For ProGAN:**
```
# load weight and make prediction
```
## 2. Dataset

the 2 Models were trained on 60,000 images from class 8 (ship) from dataset CIFAR10. In these models, we do not need a test dataset, so, I merged both train and test into one dataset. 

## 3. Results

## 3.1. GAN

GAN is trained with 201 epochs, the result is improved significantly through epochs. Below are the images that the Generator created throughout the training process:

![image](https://github.com/TruongQuynhNhu/Vanila-GAN-and-proGAN/assets/107611691/6e40b1a7-d699-4d8f-8c46-ea65de751ef8)


Below is the loss behavior of the Generator and Discriminator during the training.

![image](https://github.com/TruongQuynhNhu/Vanila-GAN-and-proGAN/assets/107611691/4a5cf564-dd90-4c32-80b4-cd8eded9ac14)

Images that is generated by the final model:

![image](https://github.com/TruongQuynhNhu/Vanila-GAN-and-proGAN/assets/107611691/295488e7-2dfd-4541-b6a6-6707b0f8ce36)

We can still observe that some ship shapes are abnormal, however, most of the images can still be recognized as ships in some way.

**Comments**: 

- When I changed the activation function of the Generator from Sigmoid to tanH and removed the BatchNorm layer from the model, the performance seemed to improve significantly.

## 3.2 ProGAN

ProGAN is trained progressively with gradually increasing resolution of the generated images (the resolution of input for the Discriminator is adjusted accordingly). The structure of G and D is built based on the images below:

![image](https://github.com/TruongQuynhNhu/Vanila-GAN-and-proGAN/assets/107611691/ed1d860f-9891-4f8c-9bcf-a4a4510d4d04)
![image](https://github.com/TruongQuynhNhu/Vanila-GAN-and-proGAN/assets/107611691/3f09a592-5406-4a20-877b-0c6a461fcb51)

[source]: Lanham, M. (2021). Advanced Generators. In: Generating a New Reality. Apress, Berkeley, CA. https://doi.org/10.1007/978-1-4842-7092-9_8_

The images generated during the training:

![image](https://github.com/TruongQuynhNhu/Vanila-GAN-and-proGAN/assets/107611691/1b690c31-101d-472a-9bbc-b5b4b945a703)


The model's loss is shown in the below image:

![image](https://github.com/TruongQuynhNhu/Vanila-GAN-and-proGAN/assets/107611691/f26e423a-d119-46f7-ba75-3dd2e98a82af)

**Comments:**

- The shape of the ships generated by the model is significantly enhanced compared to Vanilla GAN-generated images. However, the proportion of images that can be clearly identified as ships is still low. There is still a need for a lot of enhancement.

- In the PixelNorm Layer, as mentioned in the paper: b = a/l2. However, when I implemented this, it seemed to create bad NaN images. When I changed it to b = a * l2, it worked. Next time I work on this project, I will further investigate this behavior of my implementation.
  
## 4. Citation

[1] https://arxiv.org/pdf/1710.10196

[2] Fabozzi, Frank & Markowitz, Harry & Gupta, Francis. (2008). Portfolio Selection. 10.1002/9780470404324.hof002001. 

[3] https://github.com/imprasukjain/PROGAN/tree/main


